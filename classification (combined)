# 2 Classification of air quality

## Declarations
- [ ] I have gone through the CHECKLIST.qmd before submitting this exercise.

Check the following if true:

- [ ] I have used generative AI to create answers in this exercise.
- [ ] I have used generative AI as a sparring partner (or used tools such as Github Copilot).

## Prelude

The data set `pollution.csv` contains the following variables.

| Variable | Description |
| -------- | ----------- | 
| Temperature (°C)                    | Average temperature of the region. |
| Humidity (%)                        | Relative humidity recorded in the region. |
| PM2.5 Concentration (µg/m³)         | Fine particulate matter levels. |
| PM10 Concentration (µg/m³)          | Coarse particulate matter levels. |
| NO2 Concentration (ppb)             | Nitrogen dioxide levels. |
| SO2 Concentration (ppb)             | Sulfur dioxide levels. |
| CO Concentration (ppm)              | Carbon monoxide levels. |
| Proximity to Industrial Areas (km)  | Distance to the nearest industrial zone. |
| Population Density (people/km²)     | Number of people per square kilometer in the region. |
| Air Quality Levels                  | Quantification of air quality **Target**. |

```{python}
# | echo: False
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```
## 2.1 Import and investigate
::: {.callout-note icon=false appearance="simple"} 
## 
1. Import the data set `pollution.csv`. 
2. Remove every row containing missing values.
3. Make a feature matrix `X` and target vector `y`.

```{python}
import pandas as pd

data = pd.read_csv('pollution.csv')

data_cleaned = data.dropna()

X = data_cleaned.drop(columns=['Air Quality'])
y = data_cleaned['Air Quality']

print("Feature Matrix (X):")
print(X.head())

print("\nTarget Vector (y):")
print(y.head())

```

## 2.2 Inspect 
::: {.callout-note icon=false appearance="simple"} 
## 
1. Inspect the categories in the target using a suitable plotting device. 
   Is the target the imbalanced?  (I.e., the majority classes are far more prevalent than minority classes)
2. Inspect the pairplot. Display and explain any intersting patterns. 
:::

```{python}
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

file_path = 'pollution.csv'  
data = pd.read_csv(file_path)

data_cleaned = data.dropna()
target_counts = data_cleaned['Air Quality'].value_counts()

plt.figure(figsize=(8, 5))
sns.barplot(x=target_counts.index, y=target_counts.values, palette="viridis")
plt.title("Air Quality Category Distribution")
plt.xlabel("Air Quality Category")
plt.ylabel("Frequency")
plt.show()

print("Distribution of Air Quality Categories:")
print(target_counts)
print("\nClass Imbalance Ratio (Max/Min):", target_counts.max() / target_counts.min())

sns.pairplot(data_cleaned, hue='Air Quality', diag_kind='kde', corner=True, palette="coolwarm")
plt.suptitle("Pairplot of Features by Air Quality", y=1.02)
plt.show()

```
## 2.3 Logistic regression
::: {.callout-note icon=false appearance="simple"} 
## 
Remove the column `PP10` from the `pollution` dataset (and `X` and `y`). We will work with this modified data set in the remainder of the exercise.

Using cross-validation, evaluate the fit of an non-penalized logistic regression on the whole data set using (a) the negative log loss, (b) accuracy. 

What are the benefits and downsides of using the log loss vs. the accuracy?

(*Hint*: Use the argument `scoring = "neg_log_loss"`. Use the argument `warning: False` to suppress warnings in the output of a code block.)
:::

```{python}
pollution_df = pollution_df.drop(columns=['PM10'])

X = pollution_df.drop(columns=['Air Quality'], axis=1)
y = pollution_df['Air Quality']

print(X.head())
```

```{python}
print(y.head())
```

```{python}
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification 
import warnings
warnings.filterwarnings('ignore')
```

```{python}
from sklearn.model_selection import train_test_split, cross_val_score

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)
model = LogisticRegression(penalty=None)
model.fit(X_train,y_train)
```

(a) the negative log loss
```{python}
from sklearn.metrics import log_loss

# Log loss on training data
y_train_proba = model.predict_proba(X_train)
train_log_loss = log_loss(y_train, y_train_proba)
print(f"Log Loss on Training Data: {train_log_loss:.4f}")

# Cross-validation log loss
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_log_loss')
cv_log_loss_scores = -cv_scores
print("Cross-Validation Log Loss Scores for Each Fold:")
print(cv_log_loss_scores)
average_cv_log_loss = np.mean(cv_log_loss_scores)
print(f"Average Cross-Validation Log Loss: {average_cv_log_loss:.4f}")

# Log loss on test data
y_test_proba = model.predict_proba(X_test)
test_log_loss = log_loss(y_test, y_test_proba)
print(f"Log Loss on Test Data: {test_log_loss:.4f}")
```

(b) accuracy
```{python}
# Accuracy on training data
train_accuracy = model.score(X_train, y_train)
print(f"Accuracy on Training Data: {train_accuracy:.4f}")

# Cross-validation accuracy
cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f"Cross-Validation Accuracy: {cv_scores.mean():.4f}")

# Accuracy on test data
test_accuracy = model.score(X_test, y_test)
print(f"Accuracy on Test Data: {test_accuracy:.4f}")
```

Log Loss (Negative Log Loss)
Benefits:
    1. Handles Imbalanced Data: 
    Log loss is less affected by class imbalances compared to accuracy. Since it considers the predicted probabilities for all classes, it gives a more nuanced evaluation of model performance.

    2. More Granular: 
    It provides a more detailed assessment of the model’s performance. Even small improvements in probability calibration are reflected in log loss, which makes it useful for fine-tuning models.

Downsides: 
    1.  Harder to Interpret:
    It is less intuitive than accuracy because it requires understanding probabilities and logarithmic penalties.

    2. Overly Sensitive:  
    Log loss penalizes confident incorrect predictions very harshly, which can sometimes be overly sensitive to for example outliers

Accuracy 
Benefits: 
    1. Simple and Intuitive: 
    Accuracy is easy to calculate and understand, making it a popular metric for quick evaluations.
    2. Direct Measure of Performance: 
    It directly reflects the percentage of predictions that the model got right, which makes it straightforward to interpret.

Downsides: 
    1. Imbalanced Data:
    When one or more class labels are extremely common.
    Almost always the case. Think about churn prediction. Most customers don’t churn
    2. Prediction Certainty: 
    Accuracy does not take prediction certainty into account. A model predicing correctly with 51% probability can get the same score as a model with 99% probability.
    Ranking outcomes is common – call the lead with the highest probability of buying first






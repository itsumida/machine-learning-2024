# 2 Classification of air quality

## Declarations
- [ ] I have gone through the CHECKLIST.qmd before submitting this exercise.

Check the following if true:

- [ ] I have used generative AI to create answers in this exercise.
- [ ] I have used generative AI as a sparring partner (or used tools such as Github Copilot).

## Prelude

The data set `pollution.csv` contains the following variables.

| Variable | Description |
| -------- | ----------- | 
| Temperature (°C)                    | Average temperature of the region. |
| Humidity (%)                        | Relative humidity recorded in the region. |
| PM2.5 Concentration (µg/m³)         | Fine particulate matter levels. |
| PM10 Concentration (µg/m³)          | Coarse particulate matter levels. |
| NO2 Concentration (ppb)             | Nitrogen dioxide levels. |
| SO2 Concentration (ppb)             | Sulfur dioxide levels. |
| CO Concentration (ppm)              | Carbon monoxide levels. |
| Proximity to Industrial Areas (km)  | Distance to the nearest industrial zone. |
| Population Density (people/km²)     | Number of people per square kilometer in the region. |
| Air Quality Levels                  | Quantification of air quality **Target**. |

```{python}
# | echo: False
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
```
## 2.1 Import and investigate
::: {.callout-note icon=false appearance="simple"} 
## 
1. Import the data set `pollution.csv`. 
2. Remove every row containing missing values.
3. Make a feature matrix `X` and target vector `y`.

```{python}
import pandas as pd

data = pd.read_csv('pollution.csv')

data_cleaned = data.dropna()

X = data_cleaned.drop(columns=['Air Quality'])
y = data_cleaned['Air Quality']

print("Feature Matrix (X):")
print(X.head())

print("\nTarget Vector (y):")
print(y.head())

```

## 2.2 Inspect 
::: {.callout-note icon=false appearance="simple"} 
## 
1. Inspect the categories in the target using a suitable plotting device. 
   Is the target the imbalanced?  (I.e., the majority classes are far more prevalent than minority classes)
2. Inspect the pairplot. Display and explain any intersting patterns. 
:::

```{python}
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

file_path = 'pollution.csv'  
data = pd.read_csv(file_path)

data_cleaned = data.dropna()
target_counts = data_cleaned['Air Quality'].value_counts()

plt.figure(figsize=(8, 5))
sns.barplot(x=target_counts.index, y=target_counts.values, palette="viridis")
plt.title("Air Quality Category Distribution")
plt.xlabel("Air Quality Category")
plt.ylabel("Frequency")
plt.show()

print("Distribution of Air Quality Categories:")
print(target_counts)
print("\nClass Imbalance Ratio (Max/Min):", target_counts.max() / target_counts.min())

sns.pairplot(data_cleaned, hue='Air Quality', diag_kind='kde', corner=True, palette="coolwarm")
plt.suptitle("Pairplot of Features by Air Quality", y=1.02)
plt.show()

```
## 2.3 Logistic regression
::: {.callout-note icon=false appearance="simple"} 
## 
Remove the column `PP10` from the `pollution` dataset (and `X` and `y`). We will work with this modified data set in the remainder of the exercise.

Using cross-validation, evaluate the fit of an non-penalized logistic regression on the whole data set using (a) the negative log loss, (b) accuracy. 

What are the benefits and downsides of using the log loss vs. the accuracy?

(*Hint*: Use the argument `scoring = "neg_log_loss"`. Use the argument `warning: False` to suppress warnings in the output of a code block.)
:::

```{python}
pollution_df = pollution_df.drop(columns=['PM10'])

X = pollution_df.drop(columns=['Air Quality'], axis=1)
y = pollution_df['Air Quality']

print(X.head())
```

```{python}
print(y.head())
```

```{python}
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification 
import warnings
warnings.filterwarnings('ignore')
```





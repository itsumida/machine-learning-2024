# 2 Classification of air quality

## Declarations
- [ ] I have gone through the CHECKLIST.qmd before submitting this exercise.

Check the following if true:

- [ ] I have used generative AI to create answers in this exercise.
- [ ] I have used generative AI as a sparring partner (or used tools such as Github Copilot).

## Prelude

The data set `pollution.csv` contains the following variables.

| Variable | Description |
| -------- | ----------- | 
| Temperature (°C)                    | Average temperature of the region. |
| Humidity (%)                        | Relative humidity recorded in the region. |
| PM2.5 Concentration (µg/m³)         | Fine particulate matter levels. |
| PM10 Concentration (µg/m³)          | Coarse particulate matter levels. |
| NO2 Concentration (ppb)             | Nitrogen dioxide levels. |
| SO2 Concentration (ppb)             | Sulfur dioxide levels. |
| CO Concentration (ppm)              | Carbon monoxide levels. |
| Proximity to Industrial Areas (km)  | Distance to the nearest industrial zone. |
| Population Density (people/km²)     | Number of people per square kilometer in the region. |
| Air Quality Levels                  | Quantification of air quality **Target**. |

```{python}
# | echo: False
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import statsmodels.formula.api as smf

from sklearn.model_selection import cross_validate
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import PolynomialFeatures

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_validate
from sklearn.metrics import accuracy_score, log_loss
```

## 2.1 Import and investigate
::: {.callout-note icon=false appearance="simple"} 
## 
1. Import the data set `pollution.csv`. 
2. Remove every row containing missing values.
3. Make a feature matrix `X` and target vector `y`.
:::

Importing the data set `pollution.csv`:
```{python}
# | code-fold: true
pollution = pd.read_csv("pollution.csv")
pollution_df = pollution.copy()
pollution_df.head()
```

Removing every row containing missing values: 
```{python}
pollution_df = pollution_df.dropna()
```

Making a feature matrix 'X' and target vector 'y':
```{python}
X = pollution_df.drop(columns=['Air Quality'])
y = pollution_df['Air Quality']
```

```{python}
# | code-summary: Feature Matrix (X)
# | code-fold: true
print(X.head())
```

```{python}
# | code-summary: Target Vector (y)
# | code-fold: true
print(y.head())
```

## 2.2 Inspect 
::: {.callout-note icon=false appearance="simple"} 
## 
1. Inspect the categories in the target using a suitable plotting device. 
   Is the target the imbalanced?  (I.e., the majority classes are far more prevalent than minority classes)
2. Inspect the pairplot. Display and explain any interesting patterns. 
:::

Inspecting the categories in the target using a suitable plotting device: 
```{python}
# | code-summary: Air Quality Categories Distribution
# | code-fold: True
plt.figure(figsize=(10, 6))
sns.barplot(x=y.value_counts().index, y=y.value_counts().values, palette='muted')
plt.title("Distribution of Air Quality Categories")
plt.xlabel("Air Quality Categories")
plt.ylabel("Count")
plt.tight_layout()
plt.show()
```

```{python}
# | code-summary: Count of each class within target variable 
# | code-fold: True
class_counts = y.value_counts()
print(class_counts)
```

As seen from the barplot, the target is indeed imbalanced and the difference between the majority class (Good Air Quality) had a value count that is 1500 higher than the minority class (Hazardous Air Quality). 

Inspecting the pairplot:
```{python}
# | code-fold: True
sns.pairplot(pollution_df, hue='Air Quality', diag_kind='kde', corner=True, palette="coolwarm")
plt.suptitle("Pairplot of Features by Air Quality", y=1.02)
plt.show()
```

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

pollution_df = pd.read_csv('pollution.csv')

pollution_df = pollution_df.dropna()

print("Columns in dataset:", pollution_df.columns)

available_features = [
    col for col in ["Temperature", "Humidity", "PM2.5 Concentration", "PM10 Concentration", "Air Quality"]
    if col in pollution_df.columns
]
print("Selected features for pairplot:", available_features)

sns.pairplot(
    pollution_df[available_features],
    hue="Air Quality",
    diag_kind="kde",
    corner=True,
    palette="coolwarm"
)
plt.suptitle("Pairplot of Features by Air Quality", y=1.02)
plt.show()

Higher temperatures are correlated with worse air quality, particularly above 30°C. There is significant overlap between 20°C to 30°C, suggesting temperature alone may not be a strong predictor.

```{python}
# | code-summary: Proximity to Industrial Areas (km) vs. Air Quality Levels 
# | code-fold: true
sns.pairplot(pollution_df[["Proximity_to_Industrial_Areas", "Air Quality"]], hue="Air Quality")
plt.show()
```

Poorer air quality is associated with locations closer to industrial areas. Greater distance from industrial zones correlates with better air quality.

```{python}
# | code-summary: Population Density (people/km²) vs. Air Quality Levels 
# | code-fold: true
sns.pairplot(pollution_df[["Population_Density", "Air Quality"]], hue="Air Quality")
plt.show()
```

Higher population densities are linked to slightly worse air quality. However, air quality levels overlap significantly within the 280-320 people/km² range.

## 2.3 Logistic regression
::: {.callout-note icon=false appearance="simple"} 
## 
Remove the column `PP10` from the `pollution` dataset (and `X` and `y`). We will work with this modified data set in the remainder of the exercise.

Using cross-validation, evaluate the fit of an non-penalized logistic regression on the whole data set using (a) the negative log loss, (b) accuracy. 

What are the benefits and downsides of using the log loss vs. the accuracy?

(*Hint*: Use the argument `scoring = "neg_log_loss"`. Use the argument `warning: False` to suppress warnings in the output of a code block.)
:::

```{python}
pollution_df = pollution_df.drop(columns=['PM10'])

X = pollution_df.drop(columns=['Air Quality'], axis=1)
y = pollution_df['Air Quality']

print(X.head())
```

```{python}
print(y.head())
```

```{python}
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification 
import warnings
warnings.filterwarnings('ignore')
```

```{python}
from sklearn.model_selection import train_test_split, cross_val_score

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)
model = LogisticRegression(penalty=None)
model.fit(X_train,y_train)
```

(a) the negative log loss
```{python}
from sklearn.metrics import log_loss

# Log loss on training data
y_train_proba = model.predict_proba(X_train)
train_log_loss = log_loss(y_train, y_train_proba)
print(f"Log Loss on Training Data: {train_log_loss:.1f}")

# Cross-validation log loss
cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_log_loss')
cv_log_loss_scores = cv_scores
print("Cross-Validation Log Loss Scores for Each Fold:")
print(cv_log_loss_scores)
average_cv_log_loss = np.mean(cv_log_loss_scores)
print(f"Average Cross-Validation Log Loss: {average_cv_log_loss:.1f}")

# Log loss on test data
y_test_proba = model.predict_proba(X_test)
test_log_loss = log_loss(y_test, y_test_proba)
print(f"Log Loss on Test Data: {test_log_loss:.1f}")
```

(b) accuracy
```{python}
# Accuracy on training data
train_accuracy = model.score(X_train, y_train)
print(f"Accuracy on Training Data: {train_accuracy:.2f}")

# Cross-validation accuracy
cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
print(f"Cross-Validation Accuracy: {cv_scores.mean():.2f}")

# Accuracy on test data
test_accuracy = model.score(X_test, y_test)
print(f"Accuracy on Test Data: {test_accuracy:.2f}")
```

Log Loss (Negative Log Loss)
Benefits:
    1. Handles Imbalanced Data: 
    Log loss is less affected by class imbalances compared to accuracy. Since it considers the predicted probabilities for all classes, it gives a more nuanced evaluation of model performance.

    2. More Granular: 
    It provides a more detailed assessment of the model’s performance. Even small improvements in probability calibration are reflected in log loss, which makes it useful for fine-tuning models.

Downsides: 
    1.  Harder to Interpret:
    It is less intuitive than accuracy because it requires understanding probabilities and logarithmic penalties.

    2. Overly Sensitive:  
    Log loss penalizes confident incorrect predictions very harshly, which can sometimes be overly sensitive to for example outliers

Accuracy 
Benefits: 
    1. Simple and Intuitive: 
    Accuracy is easy to calculate and understand, making it a popular metric for quick evaluations.

    2. Direct Measure of Performance: 
    It directly reflects the percentage of predictions that the model got right, which makes it straightforward to interpret.

Downsides: 
    1. Imbalanced Data:
    When one or more class labels are extremely common.
    Almost always the case. Think about churn prediction. Most customers don’t churn

    2. Prediction Certainty: 
    Accuracy does not take prediction certainty into account. A model predicing correctly with 51% probability can get the same score as a model with 99% probability.
    Ranking outcomes is common – call the lead with the highest probability of buying first

## 2.4 Quadratic logistic regression
::: {.callout-note icon=false appearance="simple"} 
## 
It's natural to check for "simple" non-linearity by running quadratic logistic regressions.

1. Run a quadratic logistic regression and report its cross-validated log loss and accuracy. You have to use pipelines here.
2. Then run a quadratic logistic regression model using only interaction terms. 

Place the accuracy and log scores for these two models, and the model you made in the previous exercise, in a nicely formatted table. Which model performs best? What is happening here?
:::

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_validate
import pandas as pd

baseline_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('logistic', LogisticRegression(penalty=None, max_iter=1000))  
])

full_quadratic_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('poly', PolynomialFeatures(degree=2, include_bias=False)),
    ('logistic', LogisticRegression(penalty=None, max_iter=1000))
])

interaction_only_pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)),
    ('logistic', LogisticRegression(penalty=None, max_iter=1000))
])

scoring_metrics = ['neg_log_loss', 'accuracy']

baseline_cv_results = cross_validate(baseline_pipeline, X, y, cv=5, scoring=scoring_metrics)
full_quadratic_cv_results = cross_validate(full_quadratic_pipeline, X, y, cv=5, scoring=scoring_metrics)
interaction_only_cv_results = cross_validate(interaction_only_pipeline, X, y, cv=5, scoring=scoring_metrics)

results = {
    "Model": ["Baseline Logistic Regression", "Full Quadratic Regression", "Interaction-Only Quadratic"],
    "Negative Log Loss (Mean)": [
        round(-baseline_cv_results['test_neg_log_loss'].mean(), 2),
        round(-full_quadratic_cv_results['test_neg_log_loss'].mean(), 2),
        round(-interaction_only_cv_results['test_neg_log_loss'].mean(), 2)
    ],
    "Accuracy (Mean)": [
        round(baseline_cv_results['test_accuracy'].mean(), 2),
        round(full_quadratic_cv_results['test_accuracy'].mean(), 2),
        round(interaction_only_cv_results['test_accuracy'].mean(), 2)
    ]
}

results_df = pd.DataFrame(results)
print(results_df)


## 2.5 Boosting
::: {.callout-note icon=false appearance="simple"} 
## 
Run a boosting classifier on the data. Estimate its, performance of the classifier, and make an importance plot. Explain what you see. 
:::

```{python}
import pandas as pd
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, log_loss
import matplotlib.pyplot as plt

file_path = 'pollution.csv'  

X = pollution_df.drop(columns=['Air Quality'])  
y = pollution_df['Air Quality']  


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)

boosting_model = GradientBoostingClassifier(random_state=42)
boosting_model.fit(X_train, y_train)

y_pred_proba = boosting_model.predict_proba(X_test)
y_pred = boosting_model.predict(X_test)


accuracy = accuracy_score(y_test, y_pred)
logloss = log_loss(y_test, y_pred_proba)


print(f"Model Accuracy: {accuracy:.2f}")
print(f"Log Loss: {-logloss:.2f}")  

feature_importances = boosting_model.feature_importances_
sorted_indices = feature_importances.argsort()

plt.figure(figsize=(10, 6))
plt.barh(X.columns[sorted_indices], feature_importances[sorted_indices], color='steelblue')
plt.xlabel("Feature Importance")
plt.ylabel("Features")
plt.title("Feature Importance (Gradient Boosting Classifier)")
plt.show()

```

The Gradient Boosting Classifier performs similarly to the baseline and quadratic logistic regression models, indicating that the dataset may have limited signal or non-linear structure for significant improvement. The relatively low accuracy and high log loss suggest the model struggles to make precise predictions, potentially due to noisy or overlapping data features. Therefore The Gradient Boosting Classifier captures non-linear relationships, but the overall performance remains low.

The feature importance plot highlights which variables contribute most to the model's predictions. Features with higher importance are more influential in determining the target variable.

## 2.6 Other models
::: {.callout-note icon=false appearance="simple"} 
## 
Discuss other potential models for this data set. Do you find it likely that any of them would perform better than logistic regression?
:::

1. Decision Trees and Random Forests:
Decision Trees can capture non-linear relationships and feature interactions without assuming linearity, which is beneficial for pollution data that often exhibits such complexities. Random Forests, as an ensemble of decision trees, reduce the risk of overfitting and variance by aggregating multiple trees, providing more robust performance. Both models can handle class imbalance by adjusting class weights or using balanced sampling. However, Decision Trees may overfit, leading to poor generalization, while Random Forests, though more robust, can be computationally expensive and harder to interpret compared to logistic regression.

2. Gradient Boosting Machines (GBM):
Gradient Boosting Machines (including implementations like XGBoost and LightGBM) build trees sequentially, where each tree attempts to correct the errors of the previous one. This makes them highly effective at capturing complex relationships and non-linear patterns in data. GBMs can manage class imbalance using class weights or specialized loss functions, improving their performance in skewed datasets. However, they require careful tuning of hyperparameters and are computationally intensive, making them less interpretable than logistic regression.

3. K-Nearest Neighbors (KNN):
K-Nearest Neighbors (KNN) is a non-parametric method that captures complex decision boundaries by classifying a data point based on the majority class of its nearest neighbors. It works well for datasets with intricate relationships between features. KNN can handle class imbalance through weighted approaches, where closer neighbors have more influence. However, it is computationally expensive for large datasets and struggles with high-dimensional or noisy data, making it less efficient than other models like logistic regression in certain situations.






